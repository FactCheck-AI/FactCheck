Today we've published an open letter to online service providers operating in the UK about the increased risk of their platforms being used to stir up hatred, provoke violence and commit other offences under UK law, in the context of recent acts of violence in the UK.

Here is the letter in full:

To online service providers operating in the United Kingdom,

In the context of recent acts of violence in the UK, Ofcom has been engaging with various online services to discuss their actions to prevent their platforms from being used to stir up hatred, provoke violence and commit other offences under UK law.

Under Ofcom’s regulations that pre-date the Online Safety Act, UK-based video-sharing platforms must protect their users from videos likely to incite violence or hatred. We therefore expect video-sharing platforms to ensure their systems and processes are effective in anticipating and responding to the potential spread of harmful video material stemming from the recent events.

Additionally, as you will be aware, the Online Safety Act sets out new responsibilities for online services around how they assess and mitigate the risks of illegal activity, which can include content involving hatred, disorder, provoking violence or certain instances of disinformation. When we publish our final codes of practice and guidance, later this year, regulated services will have three months to assess the risk of illegal content on their platforms, and will then be required to take appropriate steps to stop it appearing, and act quickly to remove it when they become aware of it. Some of the most widely-used online sites and apps will in due course need to go even further – by consistently applying their terms of service, which often include banning things like hate speech, inciting violence, and harmful disinformation.

Ofcom has moved quickly to consult on risk assessment guidance and codes of practice on illegal harms, setting out the practical steps we expect services to deploy across a range of areas including governance, content moderation, user reporting and account removal. We have also published draft guidance on how companies can judge whether content or activity is illegal. As with all of our work, our proposals recognise the importance of protecting freedom of expression.

We expect continued engagement with companies over this period to understand the specific issues they face, and we welcome the proactive approaches that have been deployed by some services in relation to these acts of violence across the UK.

In a few months, new safety duties under the Online Safety Act will be in place, but you can act now – there is no need to wait to make your sites and apps safer for users.

Gill Whitehead